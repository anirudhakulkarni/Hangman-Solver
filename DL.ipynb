{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_file_location=\"words_250000_train.txt\"\n",
    "text_file = open(dictionary_file_location,\"r\")\n",
    "words = text_file.read().splitlines()\n",
    "text_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HangmanPlayer:\n",
    "    def __init__(self, word, model, lives=10):\n",
    "        self.original_word = word\n",
    "        self.full_word = [ord(i)-97 for i in word]\n",
    "        self.letters_guessed = set([])\n",
    "        self.letters_remaining = set(self.full_word)\n",
    "        self.lives_left = lives\n",
    "        self.obscured_words_seen = []\n",
    "        self.letters_previously_guessed = []\n",
    "        self.guesses = []\n",
    "        self.correct_responses = []\n",
    "        self.z = model\n",
    "        return\n",
    "    \n",
    "    def encode_obscured_word(self):\n",
    "        word = [i if i in self.letters_guessed else 26 for i in self.full_word]\n",
    "        obscured_word = np.zeros((len(word), 27), dtype=np.float32)\n",
    "        for i, j in enumerate(word):\n",
    "            obscured_word[i, j] = 1\n",
    "        return(obscured_word)\n",
    "    \n",
    "    def encode_guess(self, guess):\n",
    "        encoded_guess = np.zeros(26, dtype=np.float32)\n",
    "        encoded_guess[guess] = 1\n",
    "        return(encoded_guess)\n",
    "\n",
    "    def encode_previous_guesses(self):\n",
    "        # Create a 1 x 26 vector where 1s indicate that the letter was previously guessed\n",
    "        guess = np.zeros(26, dtype=np.float32)\n",
    "        for i in self.letters_guessed:\n",
    "            guess[i] = 1\n",
    "        return(guess)\n",
    "    \n",
    "    def encode_correct_responses(self):\n",
    "        # To be used with cross_entropy_with_softmax, this vector must be normalized\n",
    "        response = np.zeros(26, dtype=np.float32)\n",
    "        for i in self.letters_remaining:\n",
    "            response[i] = 1.0\n",
    "        response /= response.sum()\n",
    "        return(response)\n",
    "    \n",
    "    def store_guess_and_result(self, guess):\n",
    "        # Record what the model saw as input: an obscured word and a list of previously-guessed letters\n",
    "        self.obscured_words_seen.append(self.encode_obscured_word())\n",
    "        self.letters_previously_guessed.append(self.encode_previous_guesses())\n",
    "        \n",
    "        # Record the letter that the model guessed, and add that guess to the list of previous guesses\n",
    "        self.guesses.append(guess)\n",
    "        self.letters_guessed.add(guess)\n",
    "        \n",
    "        # Store the \"correct responses\"\n",
    "        correct_responses = self.encode_correct_responses()\n",
    "        self.correct_responses.append(correct_responses)\n",
    "        \n",
    "        # Determine an appropriate reward, and reduce # of lives left if appropriate\n",
    "        if guess in self.letters_remaining:\n",
    "            self.letters_remaining.remove(guess)\n",
    "        \n",
    "        if self.correct_responses[-1][guess] < 0.00001:\n",
    "            self.lives_left -= 1\n",
    "        return\n",
    "                \n",
    "    def run(self):\n",
    "        # Play a game until we run out of lives or letters\n",
    "        while (self.lives_left > 0) and (len(self.letters_remaining) > 0):\n",
    "            guess = np.argmax(np.squeeze(self.z.eval({self.z.arguments[0]: np.array(self.encode_obscured_word()),\n",
    "                                                      self.z.arguments[1]: np.array(self.encode_previous_guesses())})))\n",
    "            self.store_guess_and_result(guess)\n",
    "        \n",
    "        # Return the observations for use in training (both inputs, predictions, and losses)\n",
    "        return(np.array(self.obscured_words_seen),\n",
    "               np.array(self.letters_previously_guessed),\n",
    "               np.array(self.correct_responses))\n",
    "    \n",
    "    def show_words_seen(self):\n",
    "        for word in self.obscured_words_seen:\n",
    "            print(''.join([chr(i + 97) if i != 26 else ' ' for i in word.argmax(axis=1)]))\n",
    "            \n",
    "    def show_guesses(self):\n",
    "        for guess in self.guesses:\n",
    "            print(chr(guess + 97))\n",
    "            \n",
    "    def play_by_play(self):\n",
    "        print('Hidden word was \"{}\"'.format(self.original_word))\n",
    "        for i in range(len(self.guesses)):\n",
    "            word_seen = ''.join([chr(i + 97) if i != 26 else ' ' for i in self.obscured_words_seen[i].argmax(axis=1)])\n",
    "            print('Guessed {} after seeing \"{}\"'.format(chr(self.guesses[i] + 97),\n",
    "                                                        word_seen))\n",
    "            \n",
    "    def evaluate_performance(self):\n",
    "        # Assumes that the run() method has already been called\n",
    "        ended_in_success = self.lives_left > 0\n",
    "        letters_in_word = set([i for i in self.original_word])\n",
    "        correct_guesses = len(letters_in_word) - len(self.letters_remaining)\n",
    "        incorrect_guesses = len(self.guesses) - correct_guesses\n",
    "        return(ended_in_success, correct_guesses, incorrect_guesses, letters_in_word)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_LSTM_net(input_obscured_word_seen, input_letters_guessed_previously):\n",
    "    with cntk.layers.default_options(initial_state = 0.1):\n",
    "        lstm_outputs = cntk.layers.Recurrence(cntk.layers.LSTM(MAX_NUM_INPUTS))(input_obscured_word_seen)\n",
    "        final_lstm_output = cntk.ops.sequence.last(lstm_outputs)\n",
    "        combined_input = cntk.ops.splice(final_lstm_output, input_letters_guessed_previously)\n",
    "        dense_layer = cntk.layers.Dense(26, name='final_dense_layer')(combined_input)\n",
    "        return(dense_layer)\n",
    "    \n",
    "input_obscured_word_seen = cntk.ops.input_variable(shape=27,\n",
    "                                                   dynamic_axes=[cntk.Axis.default_batch_axis(),\n",
    "                                                                 cntk.Axis.default_dynamic_axis()],\n",
    "                                                   name='input_obscured_word_seen')\n",
    "input_letters_guessed_previously = cntk.ops.input_variable(shape=26,\n",
    "                                                           dynamic_axes=[cntk.Axis.default_batch_axis()],\n",
    "                                                           name='input_letters_guessed_previously')\n",
    "\n",
    "z = create_LSTM_net(input_obscured_word_seen, input_letters_guessed_previously)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss and displayed metric\n",
    "input_correct_responses = cntk.ops.input_variable(shape=26,\n",
    "                                                  dynamic_axes=[cntk.Axis.default_batch_axis()],\n",
    "                                                  name='input_correct_responses')\n",
    "pe = cntk.losses.cross_entropy_with_softmax(z, input_correct_responses)\n",
    "ce = cntk.metrics.classification_error(z, input_correct_responses)\n",
    "\n",
    "learning_rate = 0.1\n",
    "lr_schedule = cntk.learners.learning_rate_schedule(learning_rate, cntk.UnitType.minibatch)\n",
    "momentum_time_constant = cntk.learners.momentum_as_time_constant_schedule(BATCH_SIZE / -np.log(0.9)) \n",
    "learner = cntk.learners.fsadagrad(z.parameters,\n",
    "                                  lr=lr_schedule,\n",
    "                                  momentum=momentum_time_constant,\n",
    "                                  unit_gain = True)\n",
    "trainer = cntk.Trainer(z, (pe, ce), learner)\n",
    "progress_printer = cntk.logging.progress_print.ProgressPrinter(freq=EPOCH_SIZE, tag='Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
